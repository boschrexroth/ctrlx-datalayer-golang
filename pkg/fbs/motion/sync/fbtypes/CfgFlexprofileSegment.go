// Code generated by the FlatBuffers compiler. DO NOT EDIT.

package fbtypes

import (
	flatbuffers "github.com/google/flatbuffers/go"
)

/// configuration of a flexprofile segment
type CfgFlexprofileSegmentT struct {
	Gain float64
	Range float64
	V0 float64
	A0 float64
	J0 float64
	V1 float64
	A1 float64
	J1 float64
	LimV float64
	LimA float64
	LimJ float64
	Lambda float64
	SyncType SegmentSyncType
	LawType SegmentLawType
	Master uint32
}

func (t *CfgFlexprofileSegmentT) Pack(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	if t == nil { return 0 }
	CfgFlexprofileSegmentStart(builder)
	CfgFlexprofileSegmentAddGain(builder, t.Gain)
	CfgFlexprofileSegmentAddRange(builder, t.Range)
	CfgFlexprofileSegmentAddV0(builder, t.V0)
	CfgFlexprofileSegmentAddA0(builder, t.A0)
	CfgFlexprofileSegmentAddJ0(builder, t.J0)
	CfgFlexprofileSegmentAddV1(builder, t.V1)
	CfgFlexprofileSegmentAddA1(builder, t.A1)
	CfgFlexprofileSegmentAddJ1(builder, t.J1)
	CfgFlexprofileSegmentAddLimV(builder, t.LimV)
	CfgFlexprofileSegmentAddLimA(builder, t.LimA)
	CfgFlexprofileSegmentAddLimJ(builder, t.LimJ)
	CfgFlexprofileSegmentAddLambda(builder, t.Lambda)
	CfgFlexprofileSegmentAddSyncType(builder, t.SyncType)
	CfgFlexprofileSegmentAddLawType(builder, t.LawType)
	CfgFlexprofileSegmentAddMaster(builder, t.Master)
	return CfgFlexprofileSegmentEnd(builder)
}

func (rcv *CfgFlexprofileSegment) UnPackTo(t *CfgFlexprofileSegmentT) {
	t.Gain = rcv.Gain()
	t.Range = rcv.Range()
	t.V0 = rcv.V0()
	t.A0 = rcv.A0()
	t.J0 = rcv.J0()
	t.V1 = rcv.V1()
	t.A1 = rcv.A1()
	t.J1 = rcv.J1()
	t.LimV = rcv.LimV()
	t.LimA = rcv.LimA()
	t.LimJ = rcv.LimJ()
	t.Lambda = rcv.Lambda()
	t.SyncType = rcv.SyncType()
	t.LawType = rcv.LawType()
	t.Master = rcv.Master()
}

func (rcv *CfgFlexprofileSegment) UnPack() *CfgFlexprofileSegmentT {
	if rcv == nil { return nil }
	t := &CfgFlexprofileSegmentT{}
	rcv.UnPackTo(t)
	return t
}

type CfgFlexprofileSegment struct {
	_tab flatbuffers.Table
}

func GetRootAsCfgFlexprofileSegment(buf []byte, offset flatbuffers.UOffsetT) *CfgFlexprofileSegment {
	n := flatbuffers.GetUOffsetT(buf[offset:])
	x := &CfgFlexprofileSegment{}
	x.Init(buf, n+offset)
	return x
}

func GetSizePrefixedRootAsCfgFlexprofileSegment(buf []byte, offset flatbuffers.UOffsetT) *CfgFlexprofileSegment {
	n := flatbuffers.GetUOffsetT(buf[offset+flatbuffers.SizeUint32:])
	x := &CfgFlexprofileSegment{}
	x.Init(buf, n+offset+flatbuffers.SizeUint32)
	return x
}

func (rcv *CfgFlexprofileSegment) Init(buf []byte, i flatbuffers.UOffsetT) {
	rcv._tab.Bytes = buf
	rcv._tab.Pos = i
}

func (rcv *CfgFlexprofileSegment) Table() flatbuffers.Table {
	return rcv._tab
}

/// Gain/hub/lift of segment - slave range  (Y)   // Units
func (rcv *CfgFlexprofileSegment) Gain() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(4))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Gain/hub/lift of segment - slave range  (Y)   // Units
func (rcv *CfgFlexprofileSegment) MutateGain(n float64) bool {
	return rcv._tab.MutateFloat64Slot(4, n)
}

/// Range of segment         - master range (X)   // Units
func (rcv *CfgFlexprofileSegment) Range() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(6))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Range of segment         - master range (X)   // Units
func (rcv *CfgFlexprofileSegment) MutateRange(n float64) bool {
	return rcv._tab.MutateFloat64Slot(6, n)
}

/// Start Velocity                                // Units/s
func (rcv *CfgFlexprofileSegment) V0() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(8))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Start Velocity                                // Units/s
func (rcv *CfgFlexprofileSegment) MutateV0(n float64) bool {
	return rcv._tab.MutateFloat64Slot(8, n)
}

/// Start Acceleration                            // Units/s²
func (rcv *CfgFlexprofileSegment) A0() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(10))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Start Acceleration                            // Units/s²
func (rcv *CfgFlexprofileSegment) MutateA0(n float64) bool {
	return rcv._tab.MutateFloat64Slot(10, n)
}

/// Start Jerk                                    // Units/s³
func (rcv *CfgFlexprofileSegment) J0() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(12))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Start Jerk                                    // Units/s³
func (rcv *CfgFlexprofileSegment) MutateJ0(n float64) bool {
	return rcv._tab.MutateFloat64Slot(12, n)
}

/// End Velocity                                  // Units/s
func (rcv *CfgFlexprofileSegment) V1() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(14))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// End Velocity                                  // Units/s
func (rcv *CfgFlexprofileSegment) MutateV1(n float64) bool {
	return rcv._tab.MutateFloat64Slot(14, n)
}

/// End Acceleration                              // Units/s²
func (rcv *CfgFlexprofileSegment) A1() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(16))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// End Acceleration                              // Units/s²
func (rcv *CfgFlexprofileSegment) MutateA1(n float64) bool {
	return rcv._tab.MutateFloat64Slot(16, n)
}

/// End Jerk                                      // Units/s³
func (rcv *CfgFlexprofileSegment) J1() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(18))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// End Jerk                                      // Units/s³
func (rcv *CfgFlexprofileSegment) MutateJ1(n float64) bool {
	return rcv._tab.MutateFloat64Slot(18, n)
}

/// Travel/Limit Velocity                         // Units/s
func (rcv *CfgFlexprofileSegment) LimV() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(20))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Travel/Limit Velocity                         // Units/s
func (rcv *CfgFlexprofileSegment) MutateLimV(n float64) bool {
	return rcv._tab.MutateFloat64Slot(20, n)
}

/// Travel/Limit Acc                              // Units/s²
func (rcv *CfgFlexprofileSegment) LimA() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(22))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Travel/Limit Acc                              // Units/s²
func (rcv *CfgFlexprofileSegment) MutateLimA(n float64) bool {
	return rcv._tab.MutateFloat64Slot(22, n)
}

/// Travel/Limit Jerk                             // Units/s³
func (rcv *CfgFlexprofileSegment) LimJ() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(24))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Travel/Limit Jerk                             // Units/s³
func (rcv *CfgFlexprofileSegment) MutateLimJ(n float64) bool {
	return rcv._tab.MutateFloat64Slot(24, n)
}

/// Inflection point (Range 0.0 to 1.0)
func (rcv *CfgFlexprofileSegment) Lambda() float64 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(26))
	if o != 0 {
		return rcv._tab.GetFloat64(o + rcv._tab.Pos)
	}
	return 0.0
}

/// Inflection point (Range 0.0 to 1.0)
func (rcv *CfgFlexprofileSegment) MutateLambda(n float64) bool {
	return rcv._tab.MutateFloat64Slot(26, n)
}

/// Camtable: point array (not used in MLC)
/// pointTable    : [double];
/// Type of the segment transition (fixed or flexible)
func (rcv *CfgFlexprofileSegment) SyncType() SegmentSyncType {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(28))
	if o != 0 {
		return SegmentSyncType(rcv._tab.GetInt8(o + rcv._tab.Pos))
	}
	return 0
}

/// Camtable: point array (not used in MLC)
/// pointTable    : [double];
/// Type of the segment transition (fixed or flexible)
func (rcv *CfgFlexprofileSegment) MutateSyncType(n SegmentSyncType) bool {
	return rcv._tab.MutateInt8Slot(28, int8(n))
}

/// Type of the law (e.g. Polynomial 5th order)
func (rcv *CfgFlexprofileSegment) LawType() SegmentLawType {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(30))
	if o != 0 {
		return SegmentLawType(rcv._tab.GetUint32(o + rcv._tab.Pos))
	}
	return 0
}

/// Type of the law (e.g. Polynomial 5th order)
func (rcv *CfgFlexprofileSegment) MutateLawType(n SegmentLawType) bool {
	return rcv._tab.MutateUint32Slot(30, uint32(n))
}

/// Type of the master (FML_MasterType - axis or time)
func (rcv *CfgFlexprofileSegment) Master() uint32 {
	o := flatbuffers.UOffsetT(rcv._tab.Offset(32))
	if o != 0 {
		return rcv._tab.GetUint32(o + rcv._tab.Pos)
	}
	return 0
}

/// Type of the master (FML_MasterType - axis or time)
func (rcv *CfgFlexprofileSegment) MutateMaster(n uint32) bool {
	return rcv._tab.MutateUint32Slot(32, n)
}

func CfgFlexprofileSegmentStart(builder *flatbuffers.Builder) {
	builder.StartObject(15)
}
func CfgFlexprofileSegmentAddGain(builder *flatbuffers.Builder, gain float64) {
	builder.PrependFloat64Slot(0, gain, 0.0)
}
func CfgFlexprofileSegmentAddRange(builder *flatbuffers.Builder, range_ float64) {
	builder.PrependFloat64Slot(1, range_, 0.0)
}
func CfgFlexprofileSegmentAddV0(builder *flatbuffers.Builder, v0 float64) {
	builder.PrependFloat64Slot(2, v0, 0.0)
}
func CfgFlexprofileSegmentAddA0(builder *flatbuffers.Builder, a0 float64) {
	builder.PrependFloat64Slot(3, a0, 0.0)
}
func CfgFlexprofileSegmentAddJ0(builder *flatbuffers.Builder, j0 float64) {
	builder.PrependFloat64Slot(4, j0, 0.0)
}
func CfgFlexprofileSegmentAddV1(builder *flatbuffers.Builder, v1 float64) {
	builder.PrependFloat64Slot(5, v1, 0.0)
}
func CfgFlexprofileSegmentAddA1(builder *flatbuffers.Builder, a1 float64) {
	builder.PrependFloat64Slot(6, a1, 0.0)
}
func CfgFlexprofileSegmentAddJ1(builder *flatbuffers.Builder, j1 float64) {
	builder.PrependFloat64Slot(7, j1, 0.0)
}
func CfgFlexprofileSegmentAddLimV(builder *flatbuffers.Builder, limV float64) {
	builder.PrependFloat64Slot(8, limV, 0.0)
}
func CfgFlexprofileSegmentAddLimA(builder *flatbuffers.Builder, limA float64) {
	builder.PrependFloat64Slot(9, limA, 0.0)
}
func CfgFlexprofileSegmentAddLimJ(builder *flatbuffers.Builder, limJ float64) {
	builder.PrependFloat64Slot(10, limJ, 0.0)
}
func CfgFlexprofileSegmentAddLambda(builder *flatbuffers.Builder, lambda float64) {
	builder.PrependFloat64Slot(11, lambda, 0.0)
}
func CfgFlexprofileSegmentAddSyncType(builder *flatbuffers.Builder, syncType SegmentSyncType) {
	builder.PrependInt8Slot(12, int8(syncType), 0)
}
func CfgFlexprofileSegmentAddLawType(builder *flatbuffers.Builder, lawType SegmentLawType) {
	builder.PrependUint32Slot(13, uint32(lawType), 0)
}
func CfgFlexprofileSegmentAddMaster(builder *flatbuffers.Builder, master uint32) {
	builder.PrependUint32Slot(14, master, 0)
}
func CfgFlexprofileSegmentEnd(builder *flatbuffers.Builder) flatbuffers.UOffsetT {
	return builder.EndObject()
}
